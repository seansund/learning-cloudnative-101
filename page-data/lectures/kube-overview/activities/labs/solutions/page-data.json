{"componentChunkName":"component---src-pages-lectures-kube-overview-activities-labs-solutions-index-mdx","path":"/lectures/kube-overview/activities/labs/solutions/","result":{"pageContext":{"frontmatter":{"title":"Kubernetes Lab Solutions","description":"Solutions for Kubernetes Labs"},"relativePagePath":"/lectures/kube-overview/activities/labs/solutions/index.mdx","titleType":"page","MdxNode":{"id":"08c9891e-f86a-5576-b51d-22f477fd7e35","children":[],"parent":"cbf61c85-3508-59f1-8969-9fa6dd33a316","internal":{"content":"---\ntitle: Kubernetes Lab Solutions\ndescription: Solutions for Kubernetes Labs\n---\n# Solutions\n<Accordion>\n\n\n<AccordionItem title=\"Pod Creation\">\n\n    apiVersion: v1\n    kind: Pod\n    metadata:\n      name: nginx\n      namespace: web\n    spec:\n      containers:\n        - name: nginx\n          image: nginx\n          command: [\"nginx\"]\n          args: [\"-g\", \"daemon off;\", \"-q\"]\n          ports:\n          - containerPort: 80\n    \n</AccordionItem>\n\n<AccordionItem title=\"Pod Configuration\">\n\n    kubectl create sa yoda-svc\n\n------------------------\n\n    apiVersion: v1\n    kind: ConfigMap\n    metadata:\n      name: yoda-service-config\n    data:\n      yoda.cfg: |-\n        yoda.baby.power=100000000\n        yoda.strength=10\n   \n------------------------\n    \n    apiVersion: v1\n    kind: Secret\n    metadata:\n      name: yoda-db-password\n    stringData:\n      password: 0penSh1ftRul3s!\n    \n------------------------\n    \n    apiVersion: v1\n    kind: Pod\n    metadata:\n      name: yoda-service\n    spec:\n      serviceAccountName: yoda-svc\n      containers:\n      - name: yoda-service\n        image: bitnami/nginx\n        volumeMounts:\n        - name: config-volume\n          mountPath: /etc/yoda-service\n        env:\n        - name: DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: yoda-db-password\n              key: password\n        resources:\n          requests:\n            memory: \"64Mi\"\n            cpu: \"250m\"\n          limits:\n            memory: \"128Mi\"\n            cpu: \"500m\"\n      volumes:\n      - name: config-volume\n        configMap:\n          name: yoda-service-config\n    \n</AccordionItem>\n\n<AccordionItem title=\"Multiple Containers\">\n\n    apiVersion: v1\n    kind: ConfigMap\n    metadata:\n      name: vader-service-ambassador-config\n    data:\n      haproxy.cfg: |-\n        global\n            daemon\n            maxconn 256\n\n        defaults\n            mode http\n            timeout connect 5000ms\n            timeout client 50000ms\n            timeout server 50000ms\n\n        listen http-in\n            bind *:80\n            server server1 127.0.0.1:8989 maxconn 32\n    \n------------------------\n\n    apiVersion: v1\n    kind: Pod\n    metadata:\n      name: vader-service\n    spec:\n      containers:\n        - name: millennium-falcon\n          image: ibmcase/millennium-falcon:1\n        - name: haproxy-ambassador\n          image: haproxy:1.7\n          ports:\n          - containerPort: 80\n          volumeMounts:\n          - name: config-volume\n            mountPath: /usr/local/etc/haproxy\n      volumes:\n      - name: config-volume\n        configMap:\n          name: vader-service-ambassador-config\n    \n------------------------\n    \n    apiVersion: v1\n    kind: Pod\n    metadata:\n      name: busybox\n    spec:\n      containers:\n        - name: myapp-container\n          image: radial/busyboxplus:curl\n          command: ['sh', '-c', 'while true; do sleep 3600; done']\n\n   Check it with\n   \n    kubectl exec busybox -- curl $(kubectl get pod vader-service -o=jsonpath='{.status.podIP}'):80\n    \n</AccordionItem>\n\n<AccordionItem title=\"Probes\">\n\n    apiVersion: v1\n    kind: Pod\n    metadata:\n      name: energy-shield-service\n    spec:\n      containers:\n      - name: energy-shield\n        image: ibmcase/energy-shield:1\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 8080\n          initialDelaySeconds: 5\n\n</AccordionItem>\n\n<AccordionItem title=\"Debugging\">\n\n   Check `STATUS` column for not Ready\n\n    kubectl get pods --all-namespaces\n\n\n   Check the description of the deployment\n\n    kubectl describe deployment hyper-drive\n\n   Save logs for broken pod\n    \n    kubectl logs <pod name> -n <namespace> > /home/cloud_user/debug/broken-pod-logs.log\n    \n   In the deployment's description you will see the following is wrong:\n   <ul>\n      <li>Selector and Label names do not match.</li>\n      <li>The Probe is TCP instead of HTTP Get.</li>\n      <li>The Service Port is 80 instead of 8080.</li>\n   </ul>\n   To fix probe, can't kubectl edit, need to delete and recreate the deployment\n\n    kubectl get deployment <deployment name> -n <namespace> -o yaml --export > hyper-drive.yml\n    \n\n   Delete pod\n    \n    kubectl delete deployment <deployment name> -n <namespace>\n\n   Edit yaml, and apply\n    \n    kubectl apply -f hyper-drive.yml -n <namespace>\n    \n\n   Verify\n\n    kubectl get deployment <deployment name> -n <namespace>\n</AccordionItem>\n\n<AccordionItem title=\"Rolling Updates\">\n\n  Update the deployment to the new version like so:\n\n    kubectl set image deployment/jedi-deployment jedi-ws=bitnamy/nginx:1.18.1 --record\n\n  Check the progress of the rolling update:\n\n    kubectl rollout status deployment/jedi-deployment\n\n  In another terminal window\n\n    kubectl get pods -w\n\n  Get a list of previous revisions.\n    \n    kubectl rollout history deployment/jedi-deployment\n\n  Undo the last revision.\n\n    kubectl rollout undo deployment/jedi-deployment\n\n  Check the status of the rollout.\n\n    kubectl rollout status deployment/jedi-deployment\n\n</AccordionItem>\n\n<AccordionItem title=\"Cron Jobs\">\n\n    apiVersion: batch/v1beta1\n    kind: CronJob\n    metadata:\n      name: xwing-cronjob\n    spec:\n      schedule: \"*/1 * * * *\"\n      jobTemplate:\n        spec:\n          template:\n            spec:\n              containers:\n              - name: xwing-status\n                image: ibmcase/xwing-status:1.0\n                args:\n                - /usr/sbin/xwing-status.sh\n              restartPolicy: OnFailure\n\n------------------------\n\n    kubectl get cronjob xwing-cronjob\n\n</AccordionItem>\n\n<AccordionItem title=\"Services\">\n\n    apiVersion: v1\n    kind: Service\n    metadata:\n        name: jedi-svc\n    spec:\n        type: NodePort\n        selector:\n          app: jedi\n        ports:\n        - protocol: TCP\n            port: 80\n            targetPort: 8080\n    \n------------------------\n\n    apiVersion: v1\n    kind: Service\n    metadata:\n      name: yoda-svc\n    spec:\n      type: ClusterIP\n      selector:\n        app: yoda\n      ports:\n      - protocol: TCP\n          port: 80\n          targetPort: 8080\n\n</AccordionItem>\n\n<AccordionItem title=\"Persistent Volumes\">\n\n        apiVersion: v1\n        kind: PersistentVolume\n        metadata:\n          name: postgresql-pv\n        spec:\n          storageClassName: localdisk\n          capacity:\n            storage: 1Gi\n          accessModes:\n            - ReadWriteOnce\n          hostPath:\n            path: \"/mnt/data\"\n\n------------------------\n\n        apiVersion: v1\n        kind: PersistentVolumeClaim\n        metadata:\n          name: postgresql-pv-claim\n        spec:\n          storageClassName: localdisk\n          accessModes:\n            - ReadWriteOnce\n          resources:\n            requests:\n              storage: 500Mi\n        \n------------------------\n\n        apiVersion: v1\n        kind: Pod\n        metadata:\n          name: postgresql-pod\n        spec:\n          containers:\n          - name: postgresql\n            image: bitnami/postgresql\n            ports:\n            - containerPort: 5432\n            env:\n            - name: MYSQL_ROOT_PASSWORD\n              value: password\n            volumeMounts:\n            - name: sql-storage\n              mountPath: /bitnami/postgresql/\n          volumes:\n          - name: sql-storage\n            persistentVolumeClaim:\n              claimName: postgresql-pv-claim\n        \n------------------------\n\n</AccordionItem>\n\n</Accordion>\n\n","type":"Mdx","contentDigest":"08a7f80abc0197b09b7f61d9bf122a83","counter":642,"owner":"gatsby-plugin-mdx"},"exports":[],"rawBody":"---\ntitle: Kubernetes Lab Solutions\ndescription: Solutions for Kubernetes Labs\n---\n# Solutions\n<Accordion>\n\n\n<AccordionItem title=\"Pod Creation\">\n\n    apiVersion: v1\n    kind: Pod\n    metadata:\n      name: nginx\n      namespace: web\n    spec:\n      containers:\n        - name: nginx\n          image: nginx\n          command: [\"nginx\"]\n          args: [\"-g\", \"daemon off;\", \"-q\"]\n          ports:\n          - containerPort: 80\n    \n</AccordionItem>\n\n<AccordionItem title=\"Pod Configuration\">\n\n    kubectl create sa yoda-svc\n\n------------------------\n\n    apiVersion: v1\n    kind: ConfigMap\n    metadata:\n      name: yoda-service-config\n    data:\n      yoda.cfg: |-\n        yoda.baby.power=100000000\n        yoda.strength=10\n   \n------------------------\n    \n    apiVersion: v1\n    kind: Secret\n    metadata:\n      name: yoda-db-password\n    stringData:\n      password: 0penSh1ftRul3s!\n    \n------------------------\n    \n    apiVersion: v1\n    kind: Pod\n    metadata:\n      name: yoda-service\n    spec:\n      serviceAccountName: yoda-svc\n      containers:\n      - name: yoda-service\n        image: bitnami/nginx\n        volumeMounts:\n        - name: config-volume\n          mountPath: /etc/yoda-service\n        env:\n        - name: DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: yoda-db-password\n              key: password\n        resources:\n          requests:\n            memory: \"64Mi\"\n            cpu: \"250m\"\n          limits:\n            memory: \"128Mi\"\n            cpu: \"500m\"\n      volumes:\n      - name: config-volume\n        configMap:\n          name: yoda-service-config\n    \n</AccordionItem>\n\n<AccordionItem title=\"Multiple Containers\">\n\n    apiVersion: v1\n    kind: ConfigMap\n    metadata:\n      name: vader-service-ambassador-config\n    data:\n      haproxy.cfg: |-\n        global\n            daemon\n            maxconn 256\n\n        defaults\n            mode http\n            timeout connect 5000ms\n            timeout client 50000ms\n            timeout server 50000ms\n\n        listen http-in\n            bind *:80\n            server server1 127.0.0.1:8989 maxconn 32\n    \n------------------------\n\n    apiVersion: v1\n    kind: Pod\n    metadata:\n      name: vader-service\n    spec:\n      containers:\n        - name: millennium-falcon\n          image: ibmcase/millennium-falcon:1\n        - name: haproxy-ambassador\n          image: haproxy:1.7\n          ports:\n          - containerPort: 80\n          volumeMounts:\n          - name: config-volume\n            mountPath: /usr/local/etc/haproxy\n      volumes:\n      - name: config-volume\n        configMap:\n          name: vader-service-ambassador-config\n    \n------------------------\n    \n    apiVersion: v1\n    kind: Pod\n    metadata:\n      name: busybox\n    spec:\n      containers:\n        - name: myapp-container\n          image: radial/busyboxplus:curl\n          command: ['sh', '-c', 'while true; do sleep 3600; done']\n\n   Check it with\n   \n    kubectl exec busybox -- curl $(kubectl get pod vader-service -o=jsonpath='{.status.podIP}'):80\n    \n</AccordionItem>\n\n<AccordionItem title=\"Probes\">\n\n    apiVersion: v1\n    kind: Pod\n    metadata:\n      name: energy-shield-service\n    spec:\n      containers:\n      - name: energy-shield\n        image: ibmcase/energy-shield:1\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 8080\n          initialDelaySeconds: 5\n\n</AccordionItem>\n\n<AccordionItem title=\"Debugging\">\n\n   Check `STATUS` column for not Ready\n\n    kubectl get pods --all-namespaces\n\n\n   Check the description of the deployment\n\n    kubectl describe deployment hyper-drive\n\n   Save logs for broken pod\n    \n    kubectl logs <pod name> -n <namespace> > /home/cloud_user/debug/broken-pod-logs.log\n    \n   In the deployment's description you will see the following is wrong:\n   <ul>\n      <li>Selector and Label names do not match.</li>\n      <li>The Probe is TCP instead of HTTP Get.</li>\n      <li>The Service Port is 80 instead of 8080.</li>\n   </ul>\n   To fix probe, can't kubectl edit, need to delete and recreate the deployment\n\n    kubectl get deployment <deployment name> -n <namespace> -o yaml --export > hyper-drive.yml\n    \n\n   Delete pod\n    \n    kubectl delete deployment <deployment name> -n <namespace>\n\n   Edit yaml, and apply\n    \n    kubectl apply -f hyper-drive.yml -n <namespace>\n    \n\n   Verify\n\n    kubectl get deployment <deployment name> -n <namespace>\n</AccordionItem>\n\n<AccordionItem title=\"Rolling Updates\">\n\n  Update the deployment to the new version like so:\n\n    kubectl set image deployment/jedi-deployment jedi-ws=bitnamy/nginx:1.18.1 --record\n\n  Check the progress of the rolling update:\n\n    kubectl rollout status deployment/jedi-deployment\n\n  In another terminal window\n\n    kubectl get pods -w\n\n  Get a list of previous revisions.\n    \n    kubectl rollout history deployment/jedi-deployment\n\n  Undo the last revision.\n\n    kubectl rollout undo deployment/jedi-deployment\n\n  Check the status of the rollout.\n\n    kubectl rollout status deployment/jedi-deployment\n\n</AccordionItem>\n\n<AccordionItem title=\"Cron Jobs\">\n\n    apiVersion: batch/v1beta1\n    kind: CronJob\n    metadata:\n      name: xwing-cronjob\n    spec:\n      schedule: \"*/1 * * * *\"\n      jobTemplate:\n        spec:\n          template:\n            spec:\n              containers:\n              - name: xwing-status\n                image: ibmcase/xwing-status:1.0\n                args:\n                - /usr/sbin/xwing-status.sh\n              restartPolicy: OnFailure\n\n------------------------\n\n    kubectl get cronjob xwing-cronjob\n\n</AccordionItem>\n\n<AccordionItem title=\"Services\">\n\n    apiVersion: v1\n    kind: Service\n    metadata:\n        name: jedi-svc\n    spec:\n        type: NodePort\n        selector:\n          app: jedi\n        ports:\n        - protocol: TCP\n            port: 80\n            targetPort: 8080\n    \n------------------------\n\n    apiVersion: v1\n    kind: Service\n    metadata:\n      name: yoda-svc\n    spec:\n      type: ClusterIP\n      selector:\n        app: yoda\n      ports:\n      - protocol: TCP\n          port: 80\n          targetPort: 8080\n\n</AccordionItem>\n\n<AccordionItem title=\"Persistent Volumes\">\n\n        apiVersion: v1\n        kind: PersistentVolume\n        metadata:\n          name: postgresql-pv\n        spec:\n          storageClassName: localdisk\n          capacity:\n            storage: 1Gi\n          accessModes:\n            - ReadWriteOnce\n          hostPath:\n            path: \"/mnt/data\"\n\n------------------------\n\n        apiVersion: v1\n        kind: PersistentVolumeClaim\n        metadata:\n          name: postgresql-pv-claim\n        spec:\n          storageClassName: localdisk\n          accessModes:\n            - ReadWriteOnce\n          resources:\n            requests:\n              storage: 500Mi\n        \n------------------------\n\n        apiVersion: v1\n        kind: Pod\n        metadata:\n          name: postgresql-pod\n        spec:\n          containers:\n          - name: postgresql\n            image: bitnami/postgresql\n            ports:\n            - containerPort: 5432\n            env:\n            - name: MYSQL_ROOT_PASSWORD\n              value: password\n            volumeMounts:\n            - name: sql-storage\n              mountPath: /bitnami/postgresql/\n          volumes:\n          - name: sql-storage\n            persistentVolumeClaim:\n              claimName: postgresql-pv-claim\n        \n------------------------\n\n</AccordionItem>\n\n</Accordion>\n\n","frontmatter":{"title":"Kubernetes Lab Solutions","description":"Solutions for Kubernetes Labs"},"fileAbsolutePath":"/home/travis/build/ibm-cloud-architecture/learning-cloudnative-101/src/pages/lectures/kube-overview/activities/labs/solutions/index.mdx"}}},"staticQueryHashes":["1364590287","2102389209","2102389209","2456312558","2746626797","2746626797","3018647132","3018647132","3037994772","3037994772","63531786","63531786","768070550"]}