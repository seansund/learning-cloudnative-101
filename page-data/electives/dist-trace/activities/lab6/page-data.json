{"componentChunkName":"component---src-pages-electives-dist-trace-activities-lab-6-index-mdx","path":"/electives/dist-trace/activities/lab6/","result":{"pageContext":{"frontmatter":{"title":"Using Jaeger in Service Mesh(Istio) with Java"},"relativePagePath":"/electives/dist-trace/activities/lab6/index.mdx","titleType":"page","MdxNode":{"id":"aae1a18a-b435-5d32-95e1-ce824efbad7f","children":[],"parent":"8c90b274-e09c-536d-822a-f2d4dba825da","internal":{"content":"---\ntitle: Using Jaeger in Service Mesh(Istio) with Java\n---\n\n### General Instructions\n\n1. Clone the git repository\n\n  ```\n  git clone https://github.com/ibm-cloud-architecture/learning-distributed-tracing-101.git\n  ```\n\n2. Change to the lab directory for **Java**\n\n  ```\n  cd learning-distributed-tracing-101.git/lab-jaeger-istio-java\n  ```\n\n## Understanding Jaeger, Service Mesh, Kiali\n\nRead the OpenShift Documentation for:\n  * [Understanding Jaeger](https://docs.openshift.com/container-platform/4.2/service_mesh/service_mesh_arch/ossm-jaeger.html)\n  * [Understanding Service Mesh](https://docs.openshift.com/container-platform/4.2/service_mesh/service_mesh_arch/understanding-ossm.html)\n  * [Understanding Kiali](https://docs.openshift.com/container-platform/4.2/service_mesh/service_mesh_arch/ossm-kiali.html)\n\n## Installing Service Mesh (Istio) Operator\n\nThe following operators and tools are installed and configured as part of the Service Mesh installation:\n\n* Jaeger operator \n* Prometheus, Grafana, and Kiali\n\nWith OpenShift 4, you can use the [CodeReady Containers](https://cloud.redhat.com/openshift/install/crc/installer-provisioned) to set up a local development cluster \n\n* [Preparing to install Red Hat OpenShift Service Mesh](https://docs.openshift.com/container-platform/4.1/service_mesh/service_mesh_install/preparing-ossm-installation.html)\n* [Installing Red Hat OpenShift Service Mesh](https://docs.openshift.com/container-platform/4.1/service_mesh/service_mesh_install/installing-ossm.html)\n\n## Verify Service Mesh installation\n\n3. Verify that istio components are installed in the namespace `istio-system`\n\n  ```\n  oc get pods -n istio-system\n  ```\n\nVerify the output:\n\n```\nNAME                                    READY   STATUS    RESTARTS   AGE\ngrafana-cf5ccd86-dtcl8                  2/2     Running   0          2m9s\nistio-citadel-7cb44f4bb-hlzdc           1/1     Running   0          5m42s\nistio-egressgateway-58f4b474c4-mlj8v    1/1     Running   0          2m50s\nistio-galley-75599dbc67-ch2tv           1/1     Running   0          4m46s\nistio-ingressgateway-769c96c46f-dlrv8   1/1     Running   0          2m50s\nistio-pilot-7bd6bc45cf-rcfdl            2/2     Running   0          3m29s\nistio-policy-56476c984b-44sw5           2/2     Running   0          4m23s\nistio-sidecar-injector-55c7bf57-x25rr   1/1     Running   0          2m34s\nistio-telemetry-d5bbd7d7b-pqv8r         2/2     Running   0          4m23s\njaeger-5d9dfdfb67-658t5                 2/2     Running   0          4m51s\nkiali-597c76cc67-5qs2d                  1/1     Running   0          52s\nprometheus-685bdbdc45-rljkq             2/2     Running   0          5m23s\n```\n\n4. Verify services in the namespace `istio-system`\n\n  ```\n  oc get services -n istio-system\n  ```\n\nVerify the output:\n\n```\nNAME                        TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                  AGE\ngrafana                     ClusterIP   172.30.100.181   <none>        3000/TCP                                 21h\nistio-citadel               ClusterIP   172.30.63.141    <none>        8060/TCP,15014/TCP                       21h\nistio-egressgateway         ClusterIP   172.30.118.88    <none>        80/TCP,443/TCP,15443/TCP                 21h\nistio-galley                ClusterIP   172.30.166.57    <none>        443/TCP,15014/TCP,9901/TCP               21h\nistio-ingressgateway        ClusterIP   172.30.57.186    <none>        15020/TCP,80/TCP,443/TCP,15443/TCP       21h\nistio-pilot                 ClusterIP   172.30.231.3     <none>        15010/TCP,15011/TCP,8080/TCP,15014/TCP   21h\nistio-policy                ClusterIP   172.30.118.207   <none>        9091/TCP,15004/TCP,15014/TCP             21h\nistio-sidecar-injector      ClusterIP   172.30.175.36    <none>        443/TCP                                  21h\nistio-telemetry             ClusterIP   172.30.107.108   <none>        9091/TCP,15004/TCP,15014/TCP,42422/TCP   21h\njaeger-agent                ClusterIP   None             <none>        5775/TCP,5778/TCP,6831/TCP,6832/TCP      21h\njaeger-collector            ClusterIP   172.30.127.247   <none>        9411/TCP,14250/TCP,14267/TCP,14268/TCP   21h\njaeger-collector-headless   ClusterIP   None             <none>        9411/TCP,14250/TCP,14267/TCP,14268/TCP   21h\njaeger-query                ClusterIP   172.30.215.78    <none>        16686/TCP                                21h\nkiali                       NodePort    172.30.46.193    <none>        20001:32087/TCP                          21h\nprometheus                  ClusterIP   172.30.5.101     <none>        9090/TCP                                 21h\nzipkin                      ClusterIP   172.30.62.142    <none>        9411/TCP                                 21h\n```\n\n5. Verify that the ServiceMeshMemberRoll includes the target namespace for example `default` as one of the `MEMBERS`\n\n  ```\n  oc get ServiceMeshMemberRoll -n istio-system\n  NAME      MEMBERS\n  default   [default bookinfo]\n  ```\n\n6. Verify routes in to the different UI dashboards for Jaeger, Grafana, and Kiali\n\n  ```\n  oc get route -n istio-system\n  ```\n\nVerify the output, make sure `jaeger-query` is using `edge` for tls termination, if not you can use `oc edit service jaeger-query -n istio-system` and change it.\n\n```\nNAME                   HOST/PORT                                            PATH   SERVICES               PORT    TERMINATION   WILDCARD\ngrafana                grafana-istio-system.apps-crc.testing                       grafana                <all>   reencrypt     None\nistio-ingressgateway   istio-ingressgateway-istio-system.apps-crc.testing          istio-ingressgateway   8080                  None\njaeger                 jaeger-istio-system.apps-crc.testing                        jaeger-query           <all>   edge          None\nkiali                  kiali-istio-system.apps-crc.testing                         kiali                  <all>   reencrypt     None\nprometheus             prometheus-istio-system.apps-crc.testing                    prometheus             <all>   reencrypt     None\n```\n\nOpen the different UIs in the browser using the route's values for HOST/PORT:\n  * Jaeger: https://jaeger-istio-system.apps-crc.testing\n  * Grafana: https://grafana-istio-system.apps-crc.testing\n  * Kiali: https://kiali-istio-system.apps-crc.testing\n\n## Deploy the Application\n\n1. Deploy the services `service-a` and `service-b`\n\nUse the file `istio-java.yaml` for Java\n\nHere is an example:\n\n  ```\n  oc apply -f istio-java.yaml -n default\n  ```\nLet's look at the file content on how the services are defined to be deployed into OpenShift cluster:\n\n```\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: service-a\n  labels:\n    app: service-a\nspec:\n  ports:\n    - port: 8080\n      name: http\n  selector:\n    app: service-a\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: service-a\n  labels:\n    app: service-a\n    version: v1\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: service-a\n  template:\n    metadata:\n      labels:\n        app: service-a\n        version: v1\n      annotations:\n        sidecar.istio.io/inject: \"true\"\n    spec:\n      containers:\n        - name: app\n          image: csantanapr/service-a-java-istio\n          #image: image-registry.openshift-image-registry.svc:5000/default/service-a-java-istio\n          env:\n            - name: JAEGER_ENDPOINT\n              value: http://jaeger-collector.istio-system.svc:14268/api/traces\n            - name: JAEGER_PROPAGATION\n              value: b3\n            - name: SERVICE_FORMATTER\n              value: service-b\n          imagePullPolicy: Always\n          ports:\n            - containerPort: 8080\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: service-b\n  labels:\n    app: service-b\nspec:\n  ports:\n    - port: 8081\n      name: http\n  selector:\n    app: service-b\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: service-b\n  labels:\n    app: service-b\n    version: v1\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: service-b\n  template:\n    metadata:\n      labels:\n        app: service-b\n        version: v1\n      annotations:\n        sidecar.istio.io/inject: \"true\"\n    spec:\n      containers:\n        - name: app\n          image: csantanapr/service-b-java-istio\n          #image: image-registry.openshift-image-registry.svc:5000/default/service-b-java-istio\n          env:\n            - name: JAEGER_ENDPOINT\n              value: http://jaeger-collector.istio-system.svc:14268/api/traces\n            - name: JAEGER_PROPAGATION\n              value: b3\n          imagePullPolicy: Always\n          ports:\n            - containerPort: 8081\n```\n\nIn the yaml deployment manifest there are few items to point out:\n\n**Ports**\n  * The port for the container is specified in the service and the container in the deployment, for example, `service-a` with port `8080` and `service-b` with port `8081`\n\n**Environment Variables**\n  * The variable `JAEGER_ENDPOINT` is specified to indicate to the Jaeger client library to send the traces using HTTP to the jaeger collector service `http://jaeger-collector.istio-system.svc:14268/api/traces` that is deployed on the namespace `istio-system`. \n  * The variable `SERVICE_FORMATTER` used by `service-a` to indicate the hostname of `service-b` that will use to format the hello message.\n  * The variable `JAEGER_PROPAGATION` is set to `b3` this is necessary because the Envoy proxy does not recognize Jaeger's default on-the-wire representation of the trace context, but it does recognize Zipkin's B3 headers. This configuration instructs the Jaeger tracer to use B3 headers instead of its default ones.\n\n* Istio has certain [Specific Requirements](https://istio.io/docs/setup/additional-setup/requirements/) the ones we used in our yaml manifest are the following:\n  * **Named service ports** \n    * The service port name starts with `http`\n  * **Deployment with app and version labels**\n    * The Pod template should have the following labels defined `app` and `version`\n\n\n2. The `pom.xml` for each service contains the dependency for Zipkin to handle the B3 headers that Istio Envoy proxy forwards, this way allowing for end to end propagation. The source code is available in their respective directories `service-a` and `service-b`, the dependencies related to opentracing in the file `pom.xml` for the service looks like this:\n\n  ```\n  <dependency>\n    <groupId>io.opentracing</groupId>\n    <artifactId>opentracing-api</artifactId>\n    <version>0.33.0</version>\n  </dependency>\n\n  <dependency>\n    <groupId>io.opentracing.contrib</groupId>\n    <artifactId>opentracing-spring-cloud-starter</artifactId>\n    <version>0.3.7</version>\n  </dependency>\n\n  <dependency>\n    <groupId>io.jaegertracing</groupId>\n    <artifactId>jaeger-client</artifactId>\n    <version>1.0.0</version>\n  </dependency>\n\n  <dependency>\n    <groupId>io.jaegertracing</groupId>\n    <artifactId>jaeger-zipkin</artifactId>\n    <version>1.0.0</version>\n  </dependency>\n  ```\n\n3. Deploy the Istio Gateway and VirtualService\n\n  ```\n  oc apply -f gateway.yaml -n default\n  ```\n\nHere is the content of `gateway.yaml`\n\n```\napiVersion: networking.istio.io/v1alpha3\nkind: Gateway\nmetadata:\n  name: distributing-tracing-gateway\nspec:\n  selector:\n    istio: ingressgateway # use istio default controller\n  servers:\n    - port:\n        number: 80\n        name: http\n        protocol: HTTP\n      hosts:\n        - \"*\"\n---\napiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n  name: distributing-tracing\nspec:\n  hosts:\n    - \"*\"\n  gateways:\n    - distributing-tracing-gateway\n  http:\n    - match:\n        - uri:\n            prefix: /sayHello\n      route:\n        - destination:\n            host: service-a\n            port:\n              number: 8080\n```\n\n4. Verify services are deployed and running:\n\n  ```\n  oc get all -l app=service-a -n default\n  oc get all -l app=service-b -n default\n  NAME                             READY     STATUS    RESTARTS   AGE\n  pod/service-a-74cd5c6496-nvllm   2/2       Running   0          6m7s\n  pod/service-b-674f96464b-hbmg7   2/2       Running   0          6m44s\n\n  NAME                TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE\n  service/service-a   ClusterIP   172.30.44.43   <none>        8080/TCP   6m7s\n  service/service-b   ClusterIP   172.30.115.93   <none>        8081/TCP   6m45s\n\n  NAME                        READY     UP-TO-DATE   AVAILABLE   AGE\n  deployment.apps/service-a   1/1       1            1           6m7s\n  deployment.apps/service-b   1/1       1            1           6m44s\n  ```\n\nNotice that under the `READY` column for pods, it shows that there are two (2/2) containers running, one of them is the istio side card proxy.\n\n5. Get the hostname for the Istio ingress gateway\n\n  ```\n  oc get route -n istio-system istio-ingressgateway \n  NAME                   HOST/PORT                                            PATH   SERVICES               PORT   TERMINATION   WILDCARD\n  istio-ingressgateway   istio-ingressgateway-istio-system.apps-crc.testing          istio-ingressgateway   8080                 None\n  ```\n\n6. Use curl or open a browser with the endpoint URL using the HOST/PORT of the route\n\n  ```\n  curl http://istio-ingressgateway-istio-system.apps-crc.testing/sayHello/Carlos\n  ```\n\nNotice in the output that the message was formatted by service-b\n\n  ```\n  Hello, from service-b Carlos!\n  ```\n\nFrom the result, you can see that `service-a` calls `service-b` and replies back.\n\n7. In the Jaeger UI select `istio-ingressgateway` or `service-a` and click **Find Traces**\n\n![istio-trace](../../images/istio-java-jaeger-traces.png)\n\nYou can see 7 Spans in a single trace starting from the `istio-ingressgateway` ending in `service-b.default`\n\n8. Click on one of the traces and expand the spans in the trace\n\n![istio-spans](../../images/istio-java-jaeger-spans.png)\n\nCheck one of the labs [Lab Jaeger - Node.js](./lab1) or [Lab Jaeger - Java](./lab2) for a more in-depth lab for Opentracing with Jaeger.\n\n9. In the Kiali UI select Graph to see a topology view of the services, you can enable traffic animation under Display to see the flow of HTTP requests\n\n![istio-kiali](../../images/istio-java-kiali.png)\n\n10. In the Grafana UI select the Dashboard *Istio Workload Dashboard* or *Istio Service Dashboard* to see monitoring and metrics data for your services\n\n![istio-grafana](../../images/istio-java-grafana.png)\n","type":"Mdx","contentDigest":"2985647d0a72e03fbb3cce99285feebc","counter":594,"owner":"gatsby-plugin-mdx"},"exports":[],"rawBody":"---\ntitle: Using Jaeger in Service Mesh(Istio) with Java\n---\n\n### General Instructions\n\n1. Clone the git repository\n\n  ```\n  git clone https://github.com/ibm-cloud-architecture/learning-distributed-tracing-101.git\n  ```\n\n2. Change to the lab directory for **Java**\n\n  ```\n  cd learning-distributed-tracing-101.git/lab-jaeger-istio-java\n  ```\n\n## Understanding Jaeger, Service Mesh, Kiali\n\nRead the OpenShift Documentation for:\n  * [Understanding Jaeger](https://docs.openshift.com/container-platform/4.2/service_mesh/service_mesh_arch/ossm-jaeger.html)\n  * [Understanding Service Mesh](https://docs.openshift.com/container-platform/4.2/service_mesh/service_mesh_arch/understanding-ossm.html)\n  * [Understanding Kiali](https://docs.openshift.com/container-platform/4.2/service_mesh/service_mesh_arch/ossm-kiali.html)\n\n## Installing Service Mesh (Istio) Operator\n\nThe following operators and tools are installed and configured as part of the Service Mesh installation:\n\n* Jaeger operator \n* Prometheus, Grafana, and Kiali\n\nWith OpenShift 4, you can use the [CodeReady Containers](https://cloud.redhat.com/openshift/install/crc/installer-provisioned) to set up a local development cluster \n\n* [Preparing to install Red Hat OpenShift Service Mesh](https://docs.openshift.com/container-platform/4.1/service_mesh/service_mesh_install/preparing-ossm-installation.html)\n* [Installing Red Hat OpenShift Service Mesh](https://docs.openshift.com/container-platform/4.1/service_mesh/service_mesh_install/installing-ossm.html)\n\n## Verify Service Mesh installation\n\n3. Verify that istio components are installed in the namespace `istio-system`\n\n  ```\n  oc get pods -n istio-system\n  ```\n\nVerify the output:\n\n```\nNAME                                    READY   STATUS    RESTARTS   AGE\ngrafana-cf5ccd86-dtcl8                  2/2     Running   0          2m9s\nistio-citadel-7cb44f4bb-hlzdc           1/1     Running   0          5m42s\nistio-egressgateway-58f4b474c4-mlj8v    1/1     Running   0          2m50s\nistio-galley-75599dbc67-ch2tv           1/1     Running   0          4m46s\nistio-ingressgateway-769c96c46f-dlrv8   1/1     Running   0          2m50s\nistio-pilot-7bd6bc45cf-rcfdl            2/2     Running   0          3m29s\nistio-policy-56476c984b-44sw5           2/2     Running   0          4m23s\nistio-sidecar-injector-55c7bf57-x25rr   1/1     Running   0          2m34s\nistio-telemetry-d5bbd7d7b-pqv8r         2/2     Running   0          4m23s\njaeger-5d9dfdfb67-658t5                 2/2     Running   0          4m51s\nkiali-597c76cc67-5qs2d                  1/1     Running   0          52s\nprometheus-685bdbdc45-rljkq             2/2     Running   0          5m23s\n```\n\n4. Verify services in the namespace `istio-system`\n\n  ```\n  oc get services -n istio-system\n  ```\n\nVerify the output:\n\n```\nNAME                        TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                  AGE\ngrafana                     ClusterIP   172.30.100.181   <none>        3000/TCP                                 21h\nistio-citadel               ClusterIP   172.30.63.141    <none>        8060/TCP,15014/TCP                       21h\nistio-egressgateway         ClusterIP   172.30.118.88    <none>        80/TCP,443/TCP,15443/TCP                 21h\nistio-galley                ClusterIP   172.30.166.57    <none>        443/TCP,15014/TCP,9901/TCP               21h\nistio-ingressgateway        ClusterIP   172.30.57.186    <none>        15020/TCP,80/TCP,443/TCP,15443/TCP       21h\nistio-pilot                 ClusterIP   172.30.231.3     <none>        15010/TCP,15011/TCP,8080/TCP,15014/TCP   21h\nistio-policy                ClusterIP   172.30.118.207   <none>        9091/TCP,15004/TCP,15014/TCP             21h\nistio-sidecar-injector      ClusterIP   172.30.175.36    <none>        443/TCP                                  21h\nistio-telemetry             ClusterIP   172.30.107.108   <none>        9091/TCP,15004/TCP,15014/TCP,42422/TCP   21h\njaeger-agent                ClusterIP   None             <none>        5775/TCP,5778/TCP,6831/TCP,6832/TCP      21h\njaeger-collector            ClusterIP   172.30.127.247   <none>        9411/TCP,14250/TCP,14267/TCP,14268/TCP   21h\njaeger-collector-headless   ClusterIP   None             <none>        9411/TCP,14250/TCP,14267/TCP,14268/TCP   21h\njaeger-query                ClusterIP   172.30.215.78    <none>        16686/TCP                                21h\nkiali                       NodePort    172.30.46.193    <none>        20001:32087/TCP                          21h\nprometheus                  ClusterIP   172.30.5.101     <none>        9090/TCP                                 21h\nzipkin                      ClusterIP   172.30.62.142    <none>        9411/TCP                                 21h\n```\n\n5. Verify that the ServiceMeshMemberRoll includes the target namespace for example `default` as one of the `MEMBERS`\n\n  ```\n  oc get ServiceMeshMemberRoll -n istio-system\n  NAME      MEMBERS\n  default   [default bookinfo]\n  ```\n\n6. Verify routes in to the different UI dashboards for Jaeger, Grafana, and Kiali\n\n  ```\n  oc get route -n istio-system\n  ```\n\nVerify the output, make sure `jaeger-query` is using `edge` for tls termination, if not you can use `oc edit service jaeger-query -n istio-system` and change it.\n\n```\nNAME                   HOST/PORT                                            PATH   SERVICES               PORT    TERMINATION   WILDCARD\ngrafana                grafana-istio-system.apps-crc.testing                       grafana                <all>   reencrypt     None\nistio-ingressgateway   istio-ingressgateway-istio-system.apps-crc.testing          istio-ingressgateway   8080                  None\njaeger                 jaeger-istio-system.apps-crc.testing                        jaeger-query           <all>   edge          None\nkiali                  kiali-istio-system.apps-crc.testing                         kiali                  <all>   reencrypt     None\nprometheus             prometheus-istio-system.apps-crc.testing                    prometheus             <all>   reencrypt     None\n```\n\nOpen the different UIs in the browser using the route's values for HOST/PORT:\n  * Jaeger: https://jaeger-istio-system.apps-crc.testing\n  * Grafana: https://grafana-istio-system.apps-crc.testing\n  * Kiali: https://kiali-istio-system.apps-crc.testing\n\n## Deploy the Application\n\n1. Deploy the services `service-a` and `service-b`\n\nUse the file `istio-java.yaml` for Java\n\nHere is an example:\n\n  ```\n  oc apply -f istio-java.yaml -n default\n  ```\nLet's look at the file content on how the services are defined to be deployed into OpenShift cluster:\n\n```\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: service-a\n  labels:\n    app: service-a\nspec:\n  ports:\n    - port: 8080\n      name: http\n  selector:\n    app: service-a\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: service-a\n  labels:\n    app: service-a\n    version: v1\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: service-a\n  template:\n    metadata:\n      labels:\n        app: service-a\n        version: v1\n      annotations:\n        sidecar.istio.io/inject: \"true\"\n    spec:\n      containers:\n        - name: app\n          image: csantanapr/service-a-java-istio\n          #image: image-registry.openshift-image-registry.svc:5000/default/service-a-java-istio\n          env:\n            - name: JAEGER_ENDPOINT\n              value: http://jaeger-collector.istio-system.svc:14268/api/traces\n            - name: JAEGER_PROPAGATION\n              value: b3\n            - name: SERVICE_FORMATTER\n              value: service-b\n          imagePullPolicy: Always\n          ports:\n            - containerPort: 8080\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: service-b\n  labels:\n    app: service-b\nspec:\n  ports:\n    - port: 8081\n      name: http\n  selector:\n    app: service-b\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: service-b\n  labels:\n    app: service-b\n    version: v1\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: service-b\n  template:\n    metadata:\n      labels:\n        app: service-b\n        version: v1\n      annotations:\n        sidecar.istio.io/inject: \"true\"\n    spec:\n      containers:\n        - name: app\n          image: csantanapr/service-b-java-istio\n          #image: image-registry.openshift-image-registry.svc:5000/default/service-b-java-istio\n          env:\n            - name: JAEGER_ENDPOINT\n              value: http://jaeger-collector.istio-system.svc:14268/api/traces\n            - name: JAEGER_PROPAGATION\n              value: b3\n          imagePullPolicy: Always\n          ports:\n            - containerPort: 8081\n```\n\nIn the yaml deployment manifest there are few items to point out:\n\n**Ports**\n  * The port for the container is specified in the service and the container in the deployment, for example, `service-a` with port `8080` and `service-b` with port `8081`\n\n**Environment Variables**\n  * The variable `JAEGER_ENDPOINT` is specified to indicate to the Jaeger client library to send the traces using HTTP to the jaeger collector service `http://jaeger-collector.istio-system.svc:14268/api/traces` that is deployed on the namespace `istio-system`. \n  * The variable `SERVICE_FORMATTER` used by `service-a` to indicate the hostname of `service-b` that will use to format the hello message.\n  * The variable `JAEGER_PROPAGATION` is set to `b3` this is necessary because the Envoy proxy does not recognize Jaeger's default on-the-wire representation of the trace context, but it does recognize Zipkin's B3 headers. This configuration instructs the Jaeger tracer to use B3 headers instead of its default ones.\n\n* Istio has certain [Specific Requirements](https://istio.io/docs/setup/additional-setup/requirements/) the ones we used in our yaml manifest are the following:\n  * **Named service ports** \n    * The service port name starts with `http`\n  * **Deployment with app and version labels**\n    * The Pod template should have the following labels defined `app` and `version`\n\n\n2. The `pom.xml` for each service contains the dependency for Zipkin to handle the B3 headers that Istio Envoy proxy forwards, this way allowing for end to end propagation. The source code is available in their respective directories `service-a` and `service-b`, the dependencies related to opentracing in the file `pom.xml` for the service looks like this:\n\n  ```\n  <dependency>\n    <groupId>io.opentracing</groupId>\n    <artifactId>opentracing-api</artifactId>\n    <version>0.33.0</version>\n  </dependency>\n\n  <dependency>\n    <groupId>io.opentracing.contrib</groupId>\n    <artifactId>opentracing-spring-cloud-starter</artifactId>\n    <version>0.3.7</version>\n  </dependency>\n\n  <dependency>\n    <groupId>io.jaegertracing</groupId>\n    <artifactId>jaeger-client</artifactId>\n    <version>1.0.0</version>\n  </dependency>\n\n  <dependency>\n    <groupId>io.jaegertracing</groupId>\n    <artifactId>jaeger-zipkin</artifactId>\n    <version>1.0.0</version>\n  </dependency>\n  ```\n\n3. Deploy the Istio Gateway and VirtualService\n\n  ```\n  oc apply -f gateway.yaml -n default\n  ```\n\nHere is the content of `gateway.yaml`\n\n```\napiVersion: networking.istio.io/v1alpha3\nkind: Gateway\nmetadata:\n  name: distributing-tracing-gateway\nspec:\n  selector:\n    istio: ingressgateway # use istio default controller\n  servers:\n    - port:\n        number: 80\n        name: http\n        protocol: HTTP\n      hosts:\n        - \"*\"\n---\napiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n  name: distributing-tracing\nspec:\n  hosts:\n    - \"*\"\n  gateways:\n    - distributing-tracing-gateway\n  http:\n    - match:\n        - uri:\n            prefix: /sayHello\n      route:\n        - destination:\n            host: service-a\n            port:\n              number: 8080\n```\n\n4. Verify services are deployed and running:\n\n  ```\n  oc get all -l app=service-a -n default\n  oc get all -l app=service-b -n default\n  NAME                             READY     STATUS    RESTARTS   AGE\n  pod/service-a-74cd5c6496-nvllm   2/2       Running   0          6m7s\n  pod/service-b-674f96464b-hbmg7   2/2       Running   0          6m44s\n\n  NAME                TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE\n  service/service-a   ClusterIP   172.30.44.43   <none>        8080/TCP   6m7s\n  service/service-b   ClusterIP   172.30.115.93   <none>        8081/TCP   6m45s\n\n  NAME                        READY     UP-TO-DATE   AVAILABLE   AGE\n  deployment.apps/service-a   1/1       1            1           6m7s\n  deployment.apps/service-b   1/1       1            1           6m44s\n  ```\n\nNotice that under the `READY` column for pods, it shows that there are two (2/2) containers running, one of them is the istio side card proxy.\n\n5. Get the hostname for the Istio ingress gateway\n\n  ```\n  oc get route -n istio-system istio-ingressgateway \n  NAME                   HOST/PORT                                            PATH   SERVICES               PORT   TERMINATION   WILDCARD\n  istio-ingressgateway   istio-ingressgateway-istio-system.apps-crc.testing          istio-ingressgateway   8080                 None\n  ```\n\n6. Use curl or open a browser with the endpoint URL using the HOST/PORT of the route\n\n  ```\n  curl http://istio-ingressgateway-istio-system.apps-crc.testing/sayHello/Carlos\n  ```\n\nNotice in the output that the message was formatted by service-b\n\n  ```\n  Hello, from service-b Carlos!\n  ```\n\nFrom the result, you can see that `service-a` calls `service-b` and replies back.\n\n7. In the Jaeger UI select `istio-ingressgateway` or `service-a` and click **Find Traces**\n\n![istio-trace](../../images/istio-java-jaeger-traces.png)\n\nYou can see 7 Spans in a single trace starting from the `istio-ingressgateway` ending in `service-b.default`\n\n8. Click on one of the traces and expand the spans in the trace\n\n![istio-spans](../../images/istio-java-jaeger-spans.png)\n\nCheck one of the labs [Lab Jaeger - Node.js](./lab1) or [Lab Jaeger - Java](./lab2) for a more in-depth lab for Opentracing with Jaeger.\n\n9. In the Kiali UI select Graph to see a topology view of the services, you can enable traffic animation under Display to see the flow of HTTP requests\n\n![istio-kiali](../../images/istio-java-kiali.png)\n\n10. In the Grafana UI select the Dashboard *Istio Workload Dashboard* or *Istio Service Dashboard* to see monitoring and metrics data for your services\n\n![istio-grafana](../../images/istio-java-grafana.png)\n","frontmatter":{"title":"Using Jaeger in Service Mesh(Istio) with Java"},"fileAbsolutePath":"/home/travis/build/ibm-cloud-architecture/learning-cloudnative-101/src/pages/electives/dist-trace/activities/lab6/index.mdx"}}},"staticQueryHashes":["1364590287","2102389209","2102389209","2456312558","2746626797","2746626797","3018647132","3018647132","3037994772","3037994772","63531786","63531786","768070550"]}